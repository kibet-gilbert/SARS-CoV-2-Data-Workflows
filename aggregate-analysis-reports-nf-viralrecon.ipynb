{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notebook for aggregating sequencving reports**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob, os, re\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import  datetime\n",
    "from ipywidgets import widgets, interactive\n",
    "from pandas import ExcelWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.today().strftime(format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Directories & Files**\n",
    "Uniqueness in directory and file names is assumed for all analyses\n",
    "\n",
    "The organisation of the `run_dir`: The directory name MUST be unique and reside anywhere inside `sars_dir` directory\n",
    " \n",
    "| Directory name | File name | File source-tool | File description |\n",
    "| :-------------- | :--------- | :---------------- | :------|\n",
    "|amplicon|`*.tsv`|Mosdepth|Per-sample amplicon depths<br> ***Cols**:chrom, start, end, region, coverage, sample*\n",
    "|\n",
    "|genome|`*.tsv`|Mosdepth|Per-sample genome depths<br> ***Cols**:chrom, start, end, coverage, sample*|\n",
    "|nextclade|several| Nextclade|All Nextclade outputs|\n",
    "|pangolin|`*.csv/*.tsv`| Pangolin|Pangolin output in two formats|\n",
    "|snpEff|`*.vcf.gz`| snpEff|Per-sample unzipped snpEff output|\n",
    "\n",
    "Additional directories created inside `run_dir`: Used in the analysis\n",
    "\n",
    "| Directory name | File name | File source-tool | File description |\n",
    "| :-------------- | :--------- | :---------------- | :------|\n",
    "|var|`k-per-gene_variant_anns.tsv`|script: `abstract_snpeff_ann_output.py`|Aggregation of individual `snpEff .vcf` outputs by abstracting gene-mutations|\n",
    "|nxt|`nxt.tsv`|Nextclade|Renamed `Nextclade .tsv` output|\n",
    "|png|`png.csv`|Pangolin|Renamed `Pangolin .csv` output|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preliminary variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars_dir = 'SARS-CoV-2' #name of root directory for all SARS-associated work\n",
    "home_dir = os.getenv('HOME') #get OS home directory\n",
    "parent_dir = glob.glob(f'{home_dir}/**/{sars_dir}', recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw metadata file\n",
    "df_rmd_cln = pd.read_excel(glob.glob(f'{parent_dir}/**/Outputs/COVID19-resultsCts-merged-cln.xlsx', recursive=True)[0]).rename(columns={'S_NUM': 'sample_name'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a func to replace spaces in the header names\n",
    "def tidy_header(df):\n",
    "    df.columns = [col.replace(' ', '_') for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define func to retrieve particular columns from a df (spaces in col names must be replaced with _ in the input col_list)\n",
    "def get_cols(df, col_list):\n",
    "    new_df = tidy_header(df)\n",
    "    return new_df[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to replace from a dictionary ('key is what is to be replaced': 'value is the replacement')\n",
    "def replace(string, substitutions):\n",
    "    substrings = sorted(substitutions, key=len, reverse=True)\n",
    "    regex = re.compile('|'.join(map(re.escape, substrings)))\n",
    "    return regex.sub(lambda match: substitutions[match.group(0)], string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to merge variants and nextclade data\n",
    "def merge_varNxt(df_var_cln, df_nxt_cln):\n",
    "    return (df_var_cln.set_index('sample_name').merge(df_nxt_cln\n",
    "          .set_index('seqName'), how='outer', left_index=True, right_index=True)\n",
    "                 .reset_index().rename(columns={'index': 'sample_name'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to merge pangolin and variants-nextclade data\n",
    "def merge_pngVxt(df_png_cln, df_varNxt):\n",
    "    return (df_png_cln.set_index('Sequence_name').merge(df_varNxt\n",
    "        .set_index('sample_name'), how='outer', left_index=True, right_index=True)\n",
    "            .reset_index().rename(columns={'index': 'Sequence_name'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to merge metadata with cts data\n",
    "def merge_rmdCts(df_rmd_cln, df_cts_cln):\n",
    "    return (df_rmd_cln.set_index('S_NUM').merge(df_cts_cln.set_index('Sample_Name'), how='outer', left_index=True, right_index=True)\n",
    "            .reset_index().rename(columns={'index': 'S_NUM'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to merge metadata and seq data\n",
    "def merge_vnpPmd(df_pngVxt, df_rmdCts):\n",
    "    return (df_pngVxt.set_index('S_NUM')\n",
    "            .merge(df_rmdCts.set_index('S_NUM'), how='left', left_index=True, right_index=True)\n",
    "                 .reset_index().rename(columns={'index': 'S_NUM'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to retrieve MoC and all mutations for the s-gene\n",
    "def get_mut_of_concern(ann_file_name, moc_list):\n",
    "\n",
    "    def intersection(x, y):\n",
    "        return list(set(x) & set(y))\n",
    "\n",
    "    moc_list = moc_list\n",
    "#     file_name = 'k-per-gene_variant_anns.tsv'\n",
    "    df = ann_file_name[['sample_name','S']]\n",
    "\n",
    "#     df = pd.read_table(f'{base_dir}/{file_name}')[['sample_name','S']]\n",
    "    mutations = []\n",
    "    moc = []\n",
    "    sample_id = []\n",
    "    for row in df.itertuples():\n",
    "        if isinstance(row.S, str):\n",
    "            sgene = row.S\n",
    "        else: \n",
    "            sgene = str(row.S)\n",
    "        substitutions = sgene.replace(' ', '').split(',')[1:-1]\n",
    "        if len(moc_list) >= len(intersection(moc_list, substitutions)) > 0:\n",
    "            intsct = intersection(moc_list, substitutions)\n",
    "            sample_name = row.sample_name\n",
    "            mutations.append(str(substitutions).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\"))\n",
    "            moc.append(str(intsct).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\"))\n",
    "            sample_id.append(sample_name)\n",
    "        else: pass \n",
    "    df = pd.DataFrame({'Sample_ID': sample_id, 'Mut_of_Concern_(S)': moc, 'All_Mutations_(S)': mutations})\n",
    "    df_fnl = df.assign(Sample_ID = df['Sample_ID'].apply(lambda x: x.split('_')[0]))\n",
    "    return df_fnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_who_lin(x):\n",
    "    if x == 'B.1.1.7':\n",
    "        return x.replace(x, 'B.1.1.7(Alpha)')\n",
    "    elif x == 'B.1.617.2':\n",
    "        return x.replace(x, 'B.1.617.2(Delta)')\n",
    "    elif x == 'B.1.351':\n",
    "        return x.replace(x, 'B.1.351(Beta)')\n",
    "    elif x == 'B.1.525':\n",
    "        return x.replace(x, 'B.1.525(Eta)')\n",
    "    elif 'AY' in str(x):\n",
    "        return str(x).replace(str(x), str(x)+'(Delta)')\n",
    "    elif x == 'B.1.1.529':\n",
    "        return x.replace(x, 'B.1.1.529(Omicron)')\n",
    "    return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variables**\n",
    "\n",
    "Reassign accordingly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = 'nf-viralrecon-v2.2' #name and version\n",
    "seq_name = 'seq23and25' #seq*\n",
    "tech = 'MiSeq' #NextSeq/MiSeq/MinION\n",
    "seq_dt = '26/11/2021' #DD/MM/YYYY\n",
    "lib_prep = 'NEBNext' #NEBNext/NEBNext_FS/COVIDSeq/Nextera_XT\n",
    "primer_set = 'ARTIC_V3' #ARTIC_V3/ARTIC_V4\n",
    "identifier = 'ILL_seq22and25' #used in naming file outputs\n",
    "run_dir = 'output_reap_mrg_run23and25_miseq' #name of the run directory containing viralcon pipeline output as implemented by Kibet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sequencing sheet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sequencing cheat sheet\n",
    "df_seq_sh = (pd.read_excel(glob.glob(f'{parent_dir}/**/SeqSampleSheets/index_cheat_sheet_{seq_name}.xlsx', recursive=True)[0], usecols=['indexing', 'plt_pos']).\n",
    "             rename(columns={'indexing': 'sample_name'}))\n",
    "df_seq_sh_fnl = df_seq_sh[df_seq_sh['sample_name'].str.contains('COV')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **QCstats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the collated file for all the multiqc output\n",
    "df_qcs_trans_cols = ['sample_name', 'Genome fraction (%)']#, 'Assembly'\n",
    "df_qcs_trans = pd.read_table(glob.glob(f'{parent_dir}/**/{run_dir}/qcs/transposed_report.tsv', recursive=True)[0])\n",
    "df_qcs_trans2 = df_qcs_trans.assign(sample_name = df_qcs_trans['Assembly'].apply(lambda x: '_'.join(x.split('_')[:-1]) if (len(x.split('_')) > 2) else x.split('_')[0]))[df_qcs_trans_cols].rename(columns={'Genome fraction (%)': 'genome_cov'})\n",
    "df_qcs_trans_fnl = df_qcs_trans2.assign(genome_cov=df_qcs_trans2['genome_cov'].replace('-', np.nan).apply(lambda x: round(float(x),1) if float(x) else np.nan)).rename(columns={'genome_cov': 'Genome fraction (%)'})\n",
    "# df_qcs_trans_fnl['Seq id'] = run_dir\n",
    "# df_qcs_fnl['Analysis type'] = 'Qcs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the collated file for all the multiqc output\n",
    "\n",
    "df_qcs_cols = ['sample_name', '# Input reads', '# Trimmed reads (fastp)',\n",
    "       '% Mapped reads', '# Mapped reads', '# Trimmed reads (iVar)', \n",
    "       'Coverage median', '% Coverage > 1x', '% Coverage > 10x',\n",
    "       'Pangolin lineage (iVar)', 'Nextclade clade (iVar)']#, 'Sample'\n",
    "\n",
    "df_qcs = pd.read_csv(glob.glob(f'{parent_dir}/**/{run_dir}/qcs/summary_variants_metrics_mqc.csv', recursive=True)[0], sep=',')\n",
    "df_qcs_fnl = df_qcs.assign(sample_name = df_qcs['Sample'].apply(lambda x: '_'.join(x.split('_')[:-1]) if (len(x.split('_')) > 2) else x.split('_')[0]))[df_qcs_cols]\n",
    "df_qcs_fnl['Seq id'] = run_dir\n",
    "# df_qcs_fnl['Analysis type'] = 'Qcs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq_qcs = df_seq_sh_fnl.merge(df_qcs_trans_fnl, left_on='sample_name', right_on='sample_name', how='left').sort_values('Genome fraction (%)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcStat = df_seq_qcs.merge(df_qcs_fnl, left_on='sample_name', right_on='sample_name', how='left').sort_values('Genome fraction (%)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq_meta = df_seq_qcs.merge(df_rmd_cln, left_on='sample_name', right_on='sample_name', how='left').sort_values('Genome fraction (%)', ascending=False)\n",
    "# df_seq_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nextclade data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Nextclade clade data\n",
    "df_nxt = pd.read_table(glob.glob(f'{parent_dir}/**/{run_dir}/nxt/nxt.tsv', recursive=True)[0])\n",
    "\n",
    "# coverage based on totalMissing col in nexclade output\n",
    "coverage = round(100 - (df_nxt['totalMissing'] / 29903) * 100, 1)\n",
    "df_nxt_cln1 = df_nxt.assign(seqName = df_nxt['seqName'].apply(lambda x: '_'.join((x.split('.')[0]).split('_')[1:-1]) if (len(x.split('_')) > 2) else (x.split('/')[0]))).rename(columns={'seqName': 'sample_name'})\n",
    "df_nxt_cln2 = df_nxt_cln1.assign(coverage = coverage)\n",
    "df_nxt_fnl = df_nxt_cln1\n",
    "df_nxt_fnl['Seq id'] = run_dir\n",
    "# df_nxt_fnl['Analysis type'] = 'Nxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextclade = df_seq_qcs.merge(df_nxt_fnl, left_on='sample_name', right_on='sample_name', how='left').sort_values('Genome fraction (%)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variants data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the collated file for all the snpEff outputs\n",
    "df_var = pd.read_csv(glob.glob(f'{parent_dir}/**/{run_dir}/var/k-per-gene_variant_anns.tsv', recursive=True)[0], sep='\\t')\n",
    "df_var_fnl = df_var.assign(sample_name = df_var['sample_name'].apply(lambda x: '_'.join(x.split('_')[:-1]) if (len(x.split('_')) > 2) else x.split('_')[0]))\n",
    "df_var_fnl['Seq id'] = run_dir\n",
    "# df_var_fnl['Analysis type'] = 'Var'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iVar_snpE = df_seq_qcs.merge(df_var_fnl, left_on='sample_name', right_on='sample_name', how='left').sort_values('Genome fraction (%)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pangolin data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pangolin lineage data\n",
    "# df_png = pd.read_csv(glob.glob(f'{parent_dir}/**/{run_dir}/png/png.csv', recursive=True)[0])\n",
    "df_png_web = pd.read_csv(glob.glob(f'{parent_dir}/**/{run_dir}/png/png_web.csv', recursive=True)[0]).rename(columns={'Sequence name': 'sample_name'})\n",
    "\n",
    "months = {'January': 'Jan', 'February': 'Feb', 'March': 'Mar',\n",
    "         'April': 'Apr', 'June': 'Jun', 'July': 'Jul', 'August': 'Aug',\n",
    "          'September': 'Sep', 'October': 'Oct', 'November': 'Nov', 'December': 'Dec'}\n",
    "# retrieve cols Sequence_name and Lineage (func get_cols replaces col names spaces with _)\n",
    "# cols = ['taxon', 'lineage', 'scorpio_call']#, 'Most_common_countries']\n",
    "# df_png_cln = get_cols(tidy_header(df_png), cols)\n",
    "# df_png_fnl = (df_png_cln.assign(taxon = df_png_cln['taxon']\n",
    "#             .apply(lambda x: '_'.join(x.split('_')[1:2]) if (len(x\n",
    "#             .split('_')) > 2) else x.split('_')[0]))).rename(columns={'taxon': 'sample_name'})\n",
    "df_png_fnl_web = (df_png_web.assign(sample_name = df_png_web['sample_name']\n",
    "                .apply(lambda x: '_'.join(x.split('_')[1:2]) if (len(x\n",
    "                .split('_')) > 2) else x.split('_')[0])))\n",
    "# df_png_fnl = df_png_cln1.assign(Date_range=df_png_cln1['Date_range'].apply(lambda x: replace(x, months) if (isinstance(x, str)) else x))\n",
    "df_png_fnl_web['Seq id'] = run_dir\n",
    "# df_png_fnl_web['Analysis type'] = 'Png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pangolin = df_seq_qcs.merge(df_png_fnl_web, left_on='sample_name', right_on='sample_name', how='left').sort_values('Genome fraction (%)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary: combining data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Merge summary data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pango_summ = pangolin[['sample_name', 'Lineage', 'Scorpio call']]\n",
    "next_summ = nextclade[['sample_name', 'clade']]\n",
    "var_s = iVar_snpE[['sample_name', 'S']]\n",
    "var_summ = var_s.assign(spike_mut = var_s['S'].map(lambda x: int(len(x.split(',')))  if isinstance(x, str) else 0))\n",
    "pango_next = pango_summ.merge(next_summ, left_on='sample_name', right_on='sample_name', how='outer')\n",
    "pn_var = pango_next.merge(var_summ, left_on='sample_name', right_on='sample_name', how='outer')\n",
    "meta_summ = df_seq_meta[['CASE_ID', 'sample_name']]\n",
    "\n",
    "df_comb = df_seq_qcs.merge(pn_var, left_on='sample_name', right_on='sample_name', how='left').sort_values('Genome fraction (%)', ascending=False)\n",
    "summary = (meta_summ.merge(df_comb, left_on='sample_name', right_on='sample_name', how='right').sort_values('Genome fraction (%)', ascending=False)\n",
    "          .rename(columns={'CASE_ID': 'Case id', 'sample_name': 'Unique lab id', 'plt_pos': 'Seq plate pos', 'clade': 'Clade', 'S': 'Spike mutations (snpEff)', 'spike_mut':'Spike mutation count'}))\n",
    "\n",
    "summary[['Seq number', 'Seq platform', 'Seq date', 'Library kit', 'Primer set', 'Analysis pipeline']] = [seq_name, tech, seq_dt, lib_prep, primer_set, pipeline]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{glob.glob(f'{parent_dir}/**/SeqReports', recursive=True)[0]}/{run_dir}.Analysis.QCstats.xlsx\")\n",
    "datasheets = [(qcStat, 'QCstats'), (pangolin, 'pangolinAnalysis'), (nextclade, 'nextcladeAnalysis'), (iVar_snpE, 'snpEffAnnotation'), (df_seq_meta, 'metaData'), (summary, 'summaryReport')]\n",
    "for datasheet in datasheets:\n",
    "    datasheet[0].to_excel(writer, sheet_name=datasheet[1], index=False, na_rep='NA', float_format='%.1f')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **County feedback data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties = df_seq_meta[['CASE_ID', 'sample_name', 'COUNT_RES']]\n",
    "reports = [('Homabay', 'HCRH'), ('Migori', 'MCRH'), ('Kisii', 'KCRH'), \n",
    "           ('Nyamira', 'NCRH'), ('Siaya', 'SCRH'), ('KCSS'), ('Bukavu', 'DRC02')]\n",
    "\n",
    "for report in reports:\n",
    "    mask1 = df_counties['COUNT_RES'] == report[0]\n",
    "    mask2 = df_counties['CASE_ID'].str.contains(report[1]) == True\n",
    "    mask3 = df_counties['CASE_ID'].str.contains(report[0]) == True\n",
    "    if len(report) != 2:\n",
    "        df_report = df_counties[mask3 == True]['sample_name']\n",
    "        writer = pd.ExcelWriter(f\"{glob.glob(f'{parent_dir}/**/CountyFeedbacks', recursive=True)[0]}/{run_dir}_{report}.Analysis.QCstats.xlsx\")\n",
    "    else:\n",
    "        df_report = df_counties[mask2 == True]['sample_name']\n",
    "        writer = pd.ExcelWriter(f\"{glob.glob(f'{parent_dir}/**/CountyFeedbacks', recursive=True)[0]}/{run_dir}_{report[0]}.Analysis.QCstats.xlsx\")\n",
    "    if len(df_report) > 0:\n",
    "        for datasheet in datasheets:\n",
    "            if datasheet[1] != 'summaryReport':\n",
    "                datasheet[0][datasheet[0]['sample_name'].isin(df_report)].to_excel(writer, sheet_name=datasheet[1], index=False, na_rep='NA', float_format='%.1f')\n",
    "            else: \n",
    "                datasheet[0][datasheet[0]['Unique lab id'].isin(df_report)].to_excel(writer, sheet_name=datasheet[1], index=False, na_rep='NA', float_format='%.1f')\n",
    "        writer.save()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
