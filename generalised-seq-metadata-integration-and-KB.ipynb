{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notebook for analysing nf pipeline output**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob, os, re\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import  datetime\n",
    "from ipywidgets import widgets, interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.today().strftime(format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Directories & Files**\n",
    "Uniqueness in directory and file names is assumed for all analyses\n",
    "\n",
    "The organisation of the `run_dir`: The directory name MUST be unique and reside anywhere inside `sars_dir` directory\n",
    " \n",
    "| Directory name | File name | File source-tool | File description |\n",
    "| :-------------- | :--------- | :---------------- | :------|\n",
    "|amplicon|`*.tsv`|Mosdepth|Per-sample amplicon depths<br> ***Cols**:chrom, start, end, region, coverage, sample*\n",
    "|\n",
    "|genome|`*.tsv`|Mosdepth|Per-sample genome depths<br> ***Cols**:chrom, start, end, coverage, sample*|\n",
    "|nextclade|several| Nextclade|All Nextclade outputs|\n",
    "|pangolin|`*.csv/*.tsv`| Pangolin|Pangolin output in two formats|\n",
    "|snpEff|`*.vcf.gz`| snpEff|Per-sample unzipped snpEff output|\n",
    "\n",
    "Additional directories created inside `run_dir`: Used in the analysis\n",
    "\n",
    "| Directory name | File name | File source-tool | File description |\n",
    "| :-------------- | :--------- | :---------------- | :------|\n",
    "|var|`k-per-gene_variant_anns.tsv`|script: `abstract_snpeff_ann_output.py`|Aggregation of individual `snpEff .vcf` outputs by abstracting gene-mutations|\n",
    "|nxt|`nxt.tsv`|Nextclade|Renamed `Nextclade .tsv` output|\n",
    "|png|`png.csv`|Pangolin|Renamed `Pangolin .csv` output|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variables**\n",
    "\n",
    "Reassign accordingly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_name = 'seq30'#seq*\n",
    "tech = 'MinION'#NextSeq/MiSeq/MinION\n",
    "seq_dt = '10/12/2021'#DD/MM/YYYY\n",
    "lib_prep = 'NEBNext'#NEBNext/NEBNext_FS/COVIDSeq/Nextera_XT\n",
    "primer_set = 'ARTIC_V3'#ARTIC_V3/ARTIC_V4\n",
    "identifier = 'ONT_seq30' #used in naming file outputs\n",
    "sars_dir = 'SARS-CoV-2' #name of root directory for all SARS-associated work\n",
    "run_dir = 'output_2021-12-10_run30_ONT2' #name of the run directory containing viralcon pipeline output as implemented by Kibet\n",
    "home_dir = os.getenv('HOME') #get OS home directory\n",
    "parent_dir = glob.glob(f'{home_dir}/**/{sars_dir}', recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a func to replace spaces in the header names\n",
    "def tidy_header(df):\n",
    "    df.columns = [col.replace(' ', '_') for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define func to retrieve particular columns from a df (spaces in col names must be replaced with _ in the input col_list)\n",
    "def get_cols(df, col_list):\n",
    "    new_df = tidy_header(df)\n",
    "    return new_df[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to replace from a dictionary ('key is what is to be replaced': 'value is the replacement')\n",
    "def replace(string, substitutions):\n",
    "    substrings = sorted(substitutions, key=len, reverse=True)\n",
    "    regex = re.compile('|'.join(map(re.escape, substrings)))\n",
    "    return regex.sub(lambda match: substitutions[match.group(0)], string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to merge variants and nextclade data\n",
    "def merge_varNxt(df_var_cln, df_nxt_cln):\n",
    "    return (df_var_cln.set_index('sample_name').merge(df_nxt_cln\n",
    "          .set_index('seqName'), how='outer', left_index=True, right_index=True)\n",
    "                 .reset_index().rename(columns={'index': 'sample_name'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to merge pangolin and variants-nextclade data\n",
    "def merge_pngVxt(df_png_cln, df_varNxt):\n",
    "    return (df_png_cln.set_index('Sequence_name').merge(df_varNxt\n",
    "        .set_index('sample_name'), how='outer', left_index=True, right_index=True)\n",
    "            .reset_index().rename(columns={'index': 'Sequence_name'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to merge metadata with cts data\n",
    "def merge_rmdCts(df_rmd_cln, df_cts_cln):\n",
    "    return (df_rmd_cln.set_index('S_NUM').merge(df_cts_cln.set_index('Sample_Name'), how='outer', left_index=True, right_index=True)\n",
    "            .reset_index().rename(columns={'index': 'S_NUM'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to merge metadata and seq data\n",
    "def merge_vnpPmd(df_pngVxt, df_rmdCts):\n",
    "    return (df_pngVxt.set_index('S_NUM')\n",
    "            .merge(df_rmdCts.set_index('S_NUM'), how='left', left_index=True, right_index=True)\n",
    "                 .reset_index().rename(columns={'index': 'S_NUM'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to retrieve MoC and all mutations for the s-gene\n",
    "def get_mut_of_concern(ann_file_name, moc_list):\n",
    "\n",
    "    def intersection(x, y):\n",
    "        return list(set(x) & set(y))\n",
    "\n",
    "    moc_list = moc_list\n",
    "#     file_name = 'k-per-gene_variant_anns.tsv'\n",
    "    df = ann_file_name[['sample_name','S']]\n",
    "\n",
    "#     df = pd.read_table(f'{base_dir}/{file_name}')[['sample_name','S']]\n",
    "    mutations = []\n",
    "    moc = []\n",
    "    sample_id = []\n",
    "    for row in df.itertuples():\n",
    "        if isinstance(row.S, str):\n",
    "            sgene = row.S\n",
    "        else: \n",
    "            sgene = str(row.S)\n",
    "        substitutions = sgene.replace(' ', '').split(',')[1:-1]\n",
    "        if len(moc_list) >= len(intersection(moc_list, substitutions)) > 0:\n",
    "            intsct = intersection(moc_list, substitutions)\n",
    "            sample_name = row.sample_name\n",
    "            mutations.append(str(substitutions).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\"))\n",
    "            moc.append(str(intsct).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\"))\n",
    "            sample_id.append(sample_name)\n",
    "        else: pass \n",
    "    df = pd.DataFrame({'Sample_ID': sample_id, 'Mut_of_Concern_(S)': moc, 'All_Mutations_(S)': mutations})\n",
    "    df_fnl = df.assign(Sample_ID = df['Sample_ID'].apply(lambda x: x.split('_')[0]))\n",
    "    return df_fnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_who_lin(x):\n",
    "    if x == 'B.1.1.7':\n",
    "        return x.replace(x, 'B.1.1.7(Alpha)')\n",
    "    elif x == 'B.1.617.2':\n",
    "        return x.replace(x, 'B.1.617.2(Delta)')\n",
    "    elif x == 'B.1.351':\n",
    "        return x.replace(x, 'B.1.351(Beta)')\n",
    "    elif x == 'B.1.525':\n",
    "        return x.replace(x, 'B.1.525(Eta)')\n",
    "    elif 'AY' in str(x):\n",
    "        return str(x).replace(str(x), str(x)+'(Delta)')\n",
    "    elif x == 'B.1.1.529':\n",
    "        return x.replace(x, 'B.1.1.529(Omicron)')\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dates(x):\n",
    "    if isinstance(x, pd.Timestamp):\n",
    "        return x#x = x.strftime(format='%d-%m-%Y')\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Depth plots**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot primer depths across samples-GK\n",
    "\n",
    "suffix = '.amplicon.regions.coverage.tsv'\n",
    "files = os.listdir(glob.glob(f'{parent_dir}/**/{run_dir}/dpt', recursive=True)[0])\n",
    "data = []\n",
    "for file in files:\n",
    "    if file.endswith(suffix):\n",
    "        data.append(file)\n",
    "    else: pass\n",
    "a = len(data)\n",
    "b, c = 1, -1\n",
    "fig, axs = plt.subplots(a, b, figsize=(20,180)) \n",
    "\n",
    "xtick = np.arange(0, 98)\n",
    "xlabel = np.arange(1, 99)\n",
    "\n",
    "for file in data:\n",
    "    c += 1\n",
    "    sample_name = file.split('_')[0]\n",
    "    sample_df = pd.read_table(glob.glob(f'{parent_dir}/**/{run_dir}/dpt/{file}', recursive=True)[0])\n",
    "    sample_df2 = sample_df[['region', 'coverage']]\n",
    "    sample_df2.plot(logy=True, ax=axs[c], sharex=True, sharey=False) \n",
    "    axs[c].legend([sample_name], loc='lower left')\n",
    "plt.xlabel('Primer name')\n",
    "plt.ylabel('Read coverage')\n",
    "plt.xticks(xtick, xlabel, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#fig.savesample_df2fig('avg_kit_coverage2.png')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot read depths-GK\n",
    "suffix = '.genome.regions.coverage.tsv'\n",
    "files = os.listdir(glob.glob(f'{parent_dir}/**/{run_dir}/dpt', recursive=True)[0])\n",
    "data = []\n",
    "for file in files:\n",
    "    if file.endswith(suffix):\n",
    "        data.append(file)\n",
    "    else: pass\n",
    "a = len(data)\n",
    "b, c = 1, -1\n",
    "\n",
    "fig, axs = plt.subplots(a, b, figsize=(20, 180))\n",
    "\n",
    "xtick = range(0, 30200, 200)\n",
    "\n",
    "for file in data:\n",
    "    c += 1\n",
    "    sample_name = file.split('_')[0]\n",
    "    try:\n",
    "        df1 = pd.read_table(glob.glob(f'{parent_dir}/**/{run_dir}/dpt/{file}', recursive=True)[0])\n",
    "        d = df1['coverage'].to_frame()\n",
    "        d.set_index(np.arange(0, 30000, 200)).plot(logy=True, ax=axs[c], sharex=True, color='orange')\n",
    "        axs[c].legend([sample_name], loc='lower left')\n",
    "        text = file.split('_')[1]\n",
    "        plt.ylabel('Read coverage')\n",
    "    except TypeError:\n",
    "            print(f'no numeric data to plot for {file}')\n",
    "    finally: pass\n",
    "plt.xlabel('Genome position')\n",
    "plt.xticks(xtick, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig('avg_kit_coverage.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variants data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the collated file for all the snpEff outputs\n",
    "df_var = pd.read_csv(glob.glob(f'{parent_dir}/**/{run_dir}/var/k-per-gene_variant_anns.tsv', recursive=True)[0], sep='\\t')\n",
    "df_var_fnl = df_var.assign(sample_name = df_var['sample_name'].apply(lambda x: '_'.join(x.split('_')[:-1]) if (len(x.split('_')) > 2) else x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_var_fnl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Genome fraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the collated file for all the multiqc output\n",
    "df_qcs_trans_cols = ['sample_name', 'Genome fraction (%)']#, 'Assembly'\n",
    "df_qcs_trans = pd.read_table(glob.glob(f'{parent_dir}/**/{run_dir}/qcs/transposed_report.tsv', recursive=True)[0])\n",
    "df_qcs_trans2 = df_qcs_trans.assign(sample_name = df_qcs_trans['Assembly'].apply(lambda x: x.split('.')[0].split('_')[0]))[df_qcs_trans_cols].rename(columns={'Genome fraction (%)': 'genome_cov'})\n",
    "df_qcs_trans_fnl = df_qcs_trans2.assign(genome_cov=df_qcs_trans2['genome_cov'].replace('-', np.nan).apply(lambda x: round(float(x),1) if float(x) else np.nan)).rename(columns={'genome_cov': 'Genome fraction (%)', 'sample_name': 'seqName'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nextclade data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Nextclade clade data\n",
    "df_nxt = pd.read_table(glob.glob(f'{parent_dir}/**/{run_dir}/nxt/nxt.tsv', recursive=True)[0])\n",
    "\n",
    "# retrieve cols seqName and clade (func get_cols replaces col name spaces with _)\n",
    "cols = ['seqName', 'clade']\n",
    "df_nxt_cln = get_cols(df_nxt, cols)\n",
    "# coverage = round(100 - (df_nxt_cln['totalMissing'] / 29903) * 100, 1)\n",
    "df_nxt_cln1 = df_nxt_cln.assign(seqName = df_nxt_cln['seqName'].apply(lambda x: x.split('_')[1].split('.')[0] if len(x.split('_')) > 2 else x.split('/')[0]))\n",
    "df_nxt_fnl = df_nxt_cln1.merge(df_qcs_trans_fnl, how='outer', left_on='seqName', right_on='seqName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nxt_fnl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pangolin data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pangolin lineage data\n",
    "df_png = pd.read_csv(glob.glob(f'{parent_dir}/**/{run_dir}/png/png.csv', recursive=True)[0])\n",
    "# base_dir_pango = '/home/ouso/nextclade_files/batch2/nextclade_files_04-04-2021_11:25'\n",
    "# file_name_pango = 'consensus_pango.xlsx'\n",
    "\n",
    "# df_png = pd.read_excel(f'{base_dir_pango}/{file_name_pango}')\n",
    "months = {'January': 'Jan', 'February': 'Feb', 'March': 'Mar',\n",
    "         'April': 'Apr', 'June': 'Jun', 'July': 'Jul', 'August': 'Aug',\n",
    "          'September': 'Sep', 'October': 'Oct', 'November': 'Nov', 'December': 'Dec'}\n",
    "# retrieve cols Sequence_name and Lineage (func get_cols replaces col names spaces with _)\n",
    "# cols = ['taxon', 'lineage', 'scorpio_call']#, 'Most_common_countries']\n",
    "cols = ['Sequence_name', 'Lineage', 'Scorpio_call']\n",
    "df_png_cln = get_cols(tidy_header(df_png), cols)\n",
    "df_png_fnl = (df_png_cln.assign(Sequence_name = df_png_cln['Sequence_name'].\n",
    "                                apply(lambda x: x.split('_')[1].split('.')[0] if len(x.split('_')) > 2 else x.split('/')[0])))\n",
    "#               drop('Sequence_name', axis=1))\n",
    "# df_png_fnl = df_png_cln1.assign(Date_range=df_png_cln1['Date_range'].apply(lambda x: replace(x, months) if (isinstance(x, str)) else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence_name</th>\n",
       "      <th>Lineage</th>\n",
       "      <th>Scorpio_call</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVC25398</td>\n",
       "      <td>AY.116</td>\n",
       "      <td>Delta (B.1.617.2-like)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVC25399</td>\n",
       "      <td>B.1.617.2</td>\n",
       "      <td>Delta (B.1.617.2-like)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVC25477</td>\n",
       "      <td>AY.46</td>\n",
       "      <td>Delta (B.1.617.2-like)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVC25478</td>\n",
       "      <td>AY.46</td>\n",
       "      <td>Delta (B.1.617.2-like)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVC25479</td>\n",
       "      <td>AY.116</td>\n",
       "      <td>Delta (B.1.617.2-like)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sequence_name    Lineage            Scorpio_call\n",
       "0     COVC25398     AY.116  Delta (B.1.617.2-like)\n",
       "1     COVC25399  B.1.617.2  Delta (B.1.617.2-like)\n",
       "2     COVC25477      AY.46  Delta (B.1.617.2-like)\n",
       "3     COVC25478      AY.46  Delta (B.1.617.2-like)\n",
       "4     COVC25479     AY.116  Delta (B.1.617.2-like)"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_png_fnl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw metadata file\n",
    "df_rmd_cln = pd.read_excel(glob.glob(f'{parent_dir}/**/Outputs/COVID19-resultsCts-merged-cln.xlsx', recursive=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_rmd_cln.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Combining data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Merge Variants and Nextclade data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the nextclade data to the pangolin data\n",
    "df_varNxt = merge_varNxt(df_var_fnl, df_nxt_fnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_varNxt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Merge pango and var-nextclade data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the variants-nextclade data to the pangolin data (prioritise pango - left join)\n",
    "df_pngVxt = merge_pngVxt(df_png_fnl, df_varNxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pngVxt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pngVxt_cols_rename = ['S_NUM', 'LIN', 'SCORP_CALL',\n",
    "       'N_VAR', 'ORF1ab', 'ORF1a', 'S', 'ORF3a', 'ORF3b', 'E', 'M', 'ORF6',\n",
    "       'ORF7a', 'ORF7b', 'ORF8', 'N', 'ORF9a', 'ORF9b', 'ORF10', 'CLADE',\n",
    "       'G_COV']\n",
    "df_pngVxt.columns = df_pngVxt_cols_rename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Merge sequence/var-nxt-png (pngVxt) and  metadata (df_rmd_cln)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge metadata with seq data\n",
    "df_vnpPmd = merge_vnpPmd(df_pngVxt, df_rmd_cln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **QC whether all samples sequenced had metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following samples may be lacking pre-seq metadata, please verify:\n",
      "{'single_barcode'}\n"
     ]
    }
   ],
   "source": [
    "codes_fnl = set(df_vnpPmd['S_NUM'])\n",
    "codes_metadata = set(df_rmd_cln['S_NUM'])\n",
    "codes_union = codes_fnl & codes_metadata\n",
    "if codes_fnl - codes_union == {}:\n",
    "    print('All the samples in the the analysis were in the pre-seq metadata')\n",
    "else:\n",
    "    print(f'The following samples may be lacking pre-seq metadata, please verify:\\n{codes_fnl - codes_union}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Re-order df_vnpPmd columns and export merged metadata and sequencing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_MS = ['CASE_ID', 'S_NUM', 'AGE_YRS', 'GEND', 'OCCU', 'NAT', 'COUNT_RES', 'TRAV_HIST',\n",
    "               'TRAV_FROM', 'QUAR_PLACE', 'SYMPS', 'DT_SAM_COLL', 'DT_SAM_RECEP', 'RESULT', \n",
    "               'DT_CONF', 'AVG_Ct', 'LIN', 'SCORP_CALL', 'CLADE', 'G_COV', 'N_VAR',\n",
    "               'S', 'ORF1ab', 'ORF1a', 'ORF3a', 'ORF3b', 'E', 'M', 'ORF6', 'ORF7a', 'ORF7b', \n",
    "               'ORF8', 'N', 'ORF9a', 'ORF9b', 'ORF10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_policy = ['CASE_ID', 'S_NUM', 'AGE_YRS', 'GEND', 'OCCU', 'NAT', 'COUNT_RES', 'TRAV_HIST',\n",
    "               'TRAV_FROM', 'QUAR_PLACE', 'SYMPS', 'DT_SAM_COLL', 'DT_SAM_RECEP', 'RESULT', \n",
    "               'DT_CONF', 'AVG_Ct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export limited metadata\n",
    "df_vnpPmd_fnl1 = df_vnpPmd[header_policy].sort_values('S_NUM').drop_duplicates('S_NUM')\n",
    "df_vnpPmd_fnl1[['SEQ#', 'SEQ_MCHN', 'DT_SEQ', 'LIB_KIT', 'PRM_SET']] = [seq_name, tech, seq_dt, lib_prep, primer_set]\n",
    "(df_vnpPmd_fnl1\n",
    ".to_excel(f\"{glob.glob(f'{parent_dir}/**/KnowledgeBrief', recursive=True)[0]}/policy-brief-M-{identifier}_{dt}.xlsx\"\n",
    "                     , index=False, na_rep='N/A', float_format='%.1f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export full metadata\n",
    "df_vnpPmd_fnl = df_vnpPmd[header_MS].sort_values('S_NUM').drop_duplicates('S_NUM')\n",
    "df_vnpPmd_fnl[['SEQ#', 'SEQ_MCHN', 'DT_SEQ', 'LIB_KIT', 'PRM_SET']] = [seq_name, tech, seq_dt, lib_prep, primer_set]\n",
    "(df_vnpPmd_fnl\n",
    ".to_excel(f\"{glob.glob(f'{parent_dir}/**/KnowledgeBrief', recursive=True)[0]}/metadata-seq-MS-{identifier}_{dt}.xlsx\"\n",
    "                     , index=False, na_rep='NA', float_format='%.1f'))\n",
    "# df_vnpPmd_fnl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **County feedback data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_meta = df_vnpPmd_fnl[['CASE_ID', 'S_NUM']]\n",
    "df_caseidSeq = df_raw_meta.merge(df_vnpPmd_fnl, how='right', left_on='S_NUM', right_on='S_NUM')#.drop('SUM_Y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = [('Homabay', 'HBCTRH'), ('Migori', 'MCRH'), ('Kisii', 'KCRH'), \n",
    "           ('Nyamira', 'NCRH'), ('Siaya', 'SCRH'), ('KCSS')]\n",
    "\n",
    "for report in reports:\n",
    "    mask1 = df_vnpPmd_fnl['COUNT_RES'] == report[0]\n",
    "    mask2 = df_vnpPmd_fnl['CASE_ID'].str.contains(report[1]) == True\n",
    "    mask3 = df_vnpPmd_fnl['CASE_ID'].str.contains(report[0]) == True\n",
    "    if len(report) != 2:\n",
    "        df_report = df_vnpPmd_fnl[mask3 == True]\n",
    "    else:\n",
    "        df_report = df_vnpPmd_fnl[mask2 == True]\n",
    "    if df_report.shape[0] > 0:\n",
    "        df_report.to_excel(f\"{glob.glob(f'{parent_dir}/CountyFeedbacks')[0]}/{seq_name}-results-{report[0]}_{dt}.xlsx\", index=False, float_format='%.1f')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CDC VoI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "omicron = ['A67V', 'del69-70', 'T95I', 'del142-144', 'Y145D', 'del211', 'L212I', 'ins214EPE', 'G339D', 'S371L', 'S373P', 'S375F', \n",
    "           'K417N', 'N440K', 'G446S', 'S477N', 'T478K', 'E484A', 'Q493R', 'G496S', 'Q498R', 'N501Y', 'Y505H', 'T547K', 'D614G', \n",
    "           'H655Y', 'N679K', 'P681H', 'N764K', 'D796Y', 'N856K', 'Q954H', 'N969K', 'L981F']\n",
    "gamma = ['L18F', 'T20N', 'P26S', 'D138Y', 'R190S', 'K417T', 'E484K', 'N501Y', 'D614G', 'H655Y', 'T1027I']\n",
    "delta = ['T19R', '(V70F*)', 'T95I', 'G142D', 'E156-', 'F157-', 'R158G', '(A222V*)', '(W258L*)', '(K417N*)', \n",
    "         'L452R', 'T478K', 'D614G', 'P681R', 'D950N']\n",
    "beta = ['D80A', 'D215G', '241del', '242del', '243del', 'K417N', 'E484K', 'N501Y', 'D614G', 'A701V']\n",
    "alpha = ['69del', '70del', '144del', '(E484K*)', '(S494P*)', 'N501Y', 'A570D', 'D614G', 'P681H', 'T716I', 'S982A', 'D1118H', '(K1191N*)']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set(gamma) & set(delta) & set(beta) & set(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CDC VoC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "B16173 = ['T19R', 'G142D', 'L452R', 'E484Q', 'D614G', 'P681R', 'D950N']\n",
    "kappa = ['(T95I)', 'G142D', 'E154K', 'L452R', 'E484Q', 'D614G', 'P681R', 'Q1071H']\n",
    "iota = ['L5F', '(D80G*)', 'T95I', '(Y144-*)', '(F157S*)', 'D253G', '(L452R*)', '(S477N*)', \n",
    "        'E484K', 'D614G', 'A701V', '(T859N*)', '(D950H*)', '(Q957R*)']\n",
    "eta = ['A67V', '69del', '70del', '144del', 'E484K', 'D614G', 'Q677H', 'F888L']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set(B16173) & set(kappa) & set(iota) & set(eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (set(gamma).union(set(delta)).union(set(beta)).union(set(alpha))).union(set(B16173).union(set(kappa)).union(set(iota)).union(set(eta)))\n",
    "# x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variants of Concern or under investigation**\n",
    " - N501Y (B.1.1.7): UK variant (Alpha)\n",
    " - N501Y, E484K, *K417N (B.1.351): SA variant (Beta)\n",
    " - N501Y, E484K (P.1): Brazilian variant (Gamma)\n",
    " - P681R, E484Q, L452R (B.1.617.2): *Indian variant (Delta)\n",
    " - F157L, V367F, Q613H, P681R (A23.1): Ugandan\n",
    " - E484K, Q677H, F888L (B.1.525): Multiple (Eta)\n",
    " - L5F, T95I, D253G, A701V (B.1.526): USA (Iota)\n",
    " - G142D, E154K, Q1071H ('B.1.617.1'): Indian (Kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOH mutations of concern (spike only)\n",
    "moc_list = ['N501Y', 'E484K', 'K417N', 'P681R', 'E484Q', 'L452R', 'A570D', 'D80A', 'Q677H', 'F888L', 'L5F', 'D253G', 'E154K', 'A67V',\n",
    "           'D614G', 'D796Y', 'E484A', 'G339D', 'G446S', 'G496S', 'H655Y', 'L212I', 'L981F', 'N440K', 'N679K', 'N764K', 'N856K',\n",
    "           'N969K', 'P681H', 'Q493R', 'Q498R', 'Q954H', 'S371L', 'S373P', 'S375F', 'S477N', 'T478K', 'T547K', 'T95I', 'Y145D',\n",
    "           'Y505H',  'del142-144', 'del211', 'del69-70', 'ins214EPE']\n",
    "file_name = df_var_fnl\n",
    "df_moc = get_mut_of_concern(file_name, moc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_moc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Subsample brief data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder columns and shrink data\n",
    "cols = ['S_NUM', 'G_COV', 'DT_SAM_COLL', 'DT_SAM_RECEP', 'LIN', 'CLADE', 'SCORP_CALL', 'COUNT_RES'\n",
    "        , 'GEND', 'NAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter reporting coverage (>=70)\n",
    "df_brief = df_vnpPmd[cols][df_vnpPmd[cols]['G_COV'] >= 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_brief.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge df_brief with df_moc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brfMoc = (df_brief.merge(df_moc, how='left', left_on='S_NUM', right_on='Sample_ID'))\n",
    "df_brfMoc_fnl = (df_brfMoc.fillna('N/A')\n",
    "                 .loc[df_brfMoc['S_NUM'] != 'Undetermined']# removes \"undetermined\"\n",
    "                 .drop(['Sample_ID', 'All_Mutations_(S)'], axis=1)\n",
    "                 .drop_duplicates('S_NUM', ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Policy brief report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "cols = ['Sequence Name', 'Coverage', 'Date Collection (yyyy-mm-dd)', 'Date Received (yyyy-mm-dd)', 'Pango Lineage Annotation', 'Next Clade Lineage Annotation', 'WHO Annotation','Sample County of Origin', 'Gender', 'Subject Country of Origin', 'MoC-S-Protein']\n",
    "df_brfMoc_fnl.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_brfMoc_fnl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reformat dates for KB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brfMoc_fnl['Date Collection (yyyy-mm-dd)'] = (df_brfMoc_fnl['Date Collection (yyyy-mm-dd)']\n",
    "                                                 .map(lambda x: pd.NaT if (x == 'Nil') else format_dates(pd\n",
    "                                                      .to_datetime(x, errors='coerce', dayfirst=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brfMoc_fnl['Date Received (yyyy-mm-dd)'] = (df_brfMoc_fnl['Date Received (yyyy-mm-dd)']\n",
    "                                                 .map(lambda x: pd.NaT if (x == 'Nil') else format_dates(pd\n",
    "                                                      .to_datetime(x, errors='coerce', dayfirst=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_fnl = df_brfMoc_fnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_report_fnl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_fnl.to_excel(f\"{glob.glob(f'{parent_dir}/**/KnowledgeBrief', recursive=True)[0]}/policy-brief-T-{identifier}_{dt}.xlsx\"\n",
    "                     , index=False, na_rep='N/A', float_format='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bukavu      42\n",
       "Nyamira     15\n",
       "Nairobi     12\n",
       "Kakamega     9\n",
       "Homabay      3\n",
       "Migori       3\n",
       "Siaya        1\n",
       "Mombasa      1\n",
       "Kajiado      1\n",
       "Vihiga       1\n",
       "Name: Sample County of Origin, dtype: int64"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_report_fnl['Sample County of Origin'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_code = {'TBA48': ('lime', '#00FF00'),\n",
    " 'TBA01': ('gray', '#808080'),\n",
    " 'TBA02': ('orangered', '#FF4500'),\n",
    " 'TBA03': ('cyan', '#00FFFF'),\n",
    " 'TBA05': ('chocolate', '#D2691E'),\n",
    " 'TBA07': ('teal', '#008080'),\n",
    " 'TBA09': ('slategray', '#708090'),\n",
    " 'TBA11': ('orange', '#FFA500'),\n",
    " 'TBA13': ('seagreen', '#2E8B57'),\n",
    " 'TBA15': ('olive', '#808000'),\n",
    " 'TBA17': ('honeydew', '#FFD700'),\n",
    " 'TBA19': ('gold', '#8FBC8F'),\n",
    " 'TBA24': ('aquamarine', '#006400'),\n",
    " 'TBA25': ('yellowgreen', '#9ACD32'),\n",
    " 'TBA26': ('tan', '#D2B48C'),\n",
    " 'TBA27': ('indigo', '#4B0082'),\n",
    " 'TBA28': ('mediumpurple', '#9370DB'),\n",
    " 'TBA29': ('blue', '#0000FF'),\n",
    " 'TBA30': ('darkslateblue', '#483D8B'),\n",
    " 'TBA31': ('sienna', '#A0522D'),#'TBA32': ('darkkhaki', '#BDB76B'),\n",
    " 'TBA33': ('khaki', '#F0E68C'),\n",
    " 'TBA34': ('dodgerblue', '#1E90FF'),\n",
    " 'TBA35': ('palevioletred', '#DB7093'),\n",
    " 'TBA36': ('yellow', '#FFFF00'),\n",
    " 'TBA37': ('floralwhite', '#6495ED'),\n",
    " 'TBA38': ('green', '#008000'),\n",
    " 'TBA39': ('red', '#AFEEEE'),\n",
    " 'TBA40': ('purple', '#800080'),\n",
    " 'TBA41': ('brown', '#A52A2A'),\n",
    " 'TBA42': ('chocolate', '#D2691E'),\n",
    " 'TBA43': ('steelblue', '#4682B4'),\n",
    " 'TBA44': ('magenta', '#FF00FF'),\n",
    " 'TBA45': ('rosybrown', '#BC8F8F'),\n",
    " 'TBA46': ('goldenrod', '#DAA520'),\n",
    " 'TBA47': ('paleturquoise', '#FF0000'),\n",
    " 'TBA10': ('lavender', '#E6E6FA'),\n",
    " 'TBA12': ('pink', '#FFC0CB'),\n",
    " 'TBA14': ('seashell', '#FFFAF0'),\n",
    " 'TBA16': ('mediumvioletred', '#C71585'),\n",
    " 'TBA18': ('black', '#000000'),#'TBA2': ('cornflowerblue', '#FFF5EE'),\n",
    " 'TBA20': ('saddlebrown', '#8B4513'),\n",
    " 'TBA21': ('wheat', '#F5DEB3'),\n",
    " 'TBA22': ('slategray', '#708090'),\n",
    " 'TBA23': ('silver', '#C0C0C0'),\n",
    " 'TBA04': ('midnightblue', '#191970'),\n",
    " 'TBA06': ('darkgreen', '#7FFFD4'),\n",
    " 'TBA08': ('darkseagreen', '#F0FFF0')}#BLUES NEXT B.1.361\n",
    "avail_clr = list(clr_code.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpby_lins = (df_report_fnl.groupby('Pango Lineage Annotation')\n",
    "        .count().sort_values('Coverage', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = grpby_lins['Sequence Name'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lins = list(grpby_lins.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lin_tba =  set(lins) - set(avail_clr)\n",
    "# lin_tba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of lins to be assigned: 21\n",
      "length of colours available: 47\n"
     ]
    }
   ],
   "source": [
    "print(f'length of lins to be assigned: {len(lins)}')\n",
    "print(f'length of colours available: {len(avail_clr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clrs = {}\n",
    "for z in zip(lins, avail_clr):\n",
    "#     print(z)\n",
    "    lin_clrs[z[0]] = clr_code[z[1]][1]\n",
    "#     clr_code.pop(z[1])\n",
    "#     avail_clr.remove(z[1])\n",
    "# lin_clrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AY.110': '#9ACD32',\n",
      " 'AY.113': '#FF4500',\n",
      " 'AY.116': '#008080',\n",
      " 'AY.123': '#A0522D',\n",
      " 'AY.16': '#00FFFF',\n",
      " 'AY.43': '#483D8B',\n",
      " 'AY.44': '#0000FF',\n",
      " 'AY.46': '#00FF00',\n",
      " 'AY.46.4': '#2E8B57',\n",
      " 'AY.46.6': '#9370DB',\n",
      " 'AY.47': '#F0E68C',\n",
      " 'AY.5.4': '#4B0082',\n",
      " 'AY.55': '#808000',\n",
      " 'AY.61': '#D2B48C',\n",
      " 'AY.78': '#FFD700',\n",
      " 'AY.95': '#006400',\n",
      " 'AY.96': '#8FBC8F',\n",
      " 'B.1.1.529': '#808080',\n",
      " 'B.1.1.529 (probable)': '#708090',\n",
      " 'B.1.214.2': '#FFA500',\n",
      " 'B.1.617.2': '#D2691E'}\n"
     ]
    }
   ],
   "source": [
    "# pprint.pprint(clr_code)\n",
    "# pprint.pprint(avail_clr)\n",
    "# pprint.pprint(lin_clrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xlabels = list(map(replace_with_who_lin,list(grpby_lins.sort_index().index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "lins = (df_report_fnl.groupby('Pango Lineage Annotation').count()\n",
    " .Coverage.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "lins.index=xlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# plot lineage frequencies\n",
    "width = lins.sort_values(ascending=True)\n",
    "\n",
    "colors = [lin_clrs[lin.split('(')[0].rstrip()] for lin in list(width.index)]\n",
    "# colors = [clr[1] for clr in clr_code.values()]\n",
    "n = lins.sum()\n",
    "xticks = np.arange(0, (math.ceil(max_count / 5) + 1) * 5, 5)\n",
    "fig, ax = plt.subplots()\n",
    "# (df_report_fnl['Pango Lineage Annotation']\n",
    "#  .value_counts()\n",
    "#  .sort_values(ascending=False)\n",
    "plt.barh(width.index, width, color=colors)\n",
    "plt.title('Lineage frequencies')\n",
    "plt.ylabel('Lineages')\n",
    "plt.xticks(xticks, xticks)\n",
    "plt.yticks(width.index, fontsize=8)\n",
    "plt.xlabel(f'Counts (N={n})')\n",
    "plt.grid('major', axis='x', ls='-.')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(f'{parent_dir}/**/PlotsFigures', recursive=True)[0]}/policy-brief-Ph-{tech}_{dt}.svg\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# plot lineage frequencies\n",
    "width = lins.sort_values(ascending=False)\n",
    "\n",
    "colors = [lin_clrs[lin.split('(')[0].rstrip()] for lin in list(width.index)]\n",
    "n = df_report_fnl['Pango Lineage Annotation'].count()\n",
    "yticks = np.arange(0, (math.ceil(max_count / 5) + 1) * 5, 5)\n",
    "fig, ax = plt.subplots()\n",
    "# (df_report_fnl['Pango Lineage Annotation']\n",
    "#  .value_counts().\n",
    "width.plot(kind='bar', ax=ax, color=colors)\n",
    "plt.title('Lineage frequencies')\n",
    "plt.xlabel('Lineages')\n",
    "plt.yticks(yticks)\n",
    "plt.xticks(ticks=range(len(lins)), rotation=90, labels=width.index)\n",
    "plt.ylabel(f'Counts  (N={n})')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(f'{parent_dir}/**/PlotsFigures', recursive=True)[0]}/policy-brief-Pv-{tech}_{dt}.svg\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_order = df_report_fnl.groupby('Sample County of Origin').count()[['Sequence Name']].sort_values('Sequence Name', ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_fnl['Sample County of Origin'] = pd.Categorical(df_report_fnl['Sample County of Origin'], categories=row_order,ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_seq_summ10Ls_srt = df_report_fnl.rename(columns={'Pango Lineage Annotation':'Lineages'})#.sort_values('Sample County of Origin', ascending=False)\n",
    "fig,ax = plt.subplots(figsize=(6,4))\n",
    "# sns.set_palette(sns.color_palette(colors.values()))\n",
    "palette_clr = colors# {l: colors[l] for l in df_seq_summ10Ls_srt.Lineages.unique()}\n",
    "# sns.set_color_codes('pastel')\n",
    "sns.histplot(df_seq_summ10Ls_srt, x='Sample County of Origin', \n",
    "            hue='Lineages',multiple=\"stack\",\n",
    "             hue_order=reversed(df_report_fnl['Pango Lineage Annotation'].value_counts().index),\n",
    "           palette=palette_clr, ax=ax, legend=True)#legend=True, loc='upper right',title='Lineages', ncol=1, borderaxespad=0\n",
    "# ax.get_legend()\n",
    "l = ax.get_legend()\n",
    "h = l.legendHandles\n",
    "rotation = 0 if df_seq_summ10Ls_srt.shape[0] < 5 else 90\n",
    "plt.xticks(rotation=rotation)\n",
    "plt.ylabel(f'Counts (N={df_seq_summ10Ls_srt.shape[0]})')\n",
    "plt.xlabel('Counties')\n",
    "# l.remove()\n",
    "plt.legend(h, [t.get_text() for t in l.texts], title='Lineages', fancybox=True, ncol=2)#, loc=(1.01, 0.03)labelspacing=0.25, \n",
    "# plt.legend(df_seq_summ10Ls_srt.LIN.value_counts().sort_values(ascending=True)[-10:].index,\n",
    "#           title='Lineages', ncol=1)#, bbox_to_anchor=(1,1)\n",
    "plt.title('Lineages by counties (coverage >= 70%)', fontsize=12)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"{glob.glob(f'{parent_dir}/**/KnowledgeBrief', recursive=True)[0]}/policy-linXcounty_{seq_name}_{dt}.{ext}\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
